{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e54b5f4-3503-44fa-8f53-c389595ad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pycocotools import _mask as coco_mask\n",
    "# import zlib\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a80bd9e5-038f-46f1-a03d-f288409e7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    YOLO(\"/home/ilia_kiselev/Downloads/mix_8_cls.pt\"),\n",
    "    YOLO(\"/home/ilia_kiselev/Downloads/smooth_tal_light_002.pt\"),\n",
    "\n",
    "]\n",
    "CONF=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4be58e-e716-48c4-be10-ba7c64bd032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_binary_mask(mask: np.ndarray) -> str:\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "    # check input mask --\n",
    "    if mask.dtype != bool:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "             mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "            mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5095a81b-2166-410e-9ab1-48ba36b54633",
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = []\n",
    "def return_default_value_if_fails(default_value):\n",
    "\n",
    "    def decorator(func):\n",
    "        def inner(*args, **kwargs):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                fails.append((func, (args, kwargs), e))\n",
    "                return default_value\n",
    "        return inner\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72250eab-337e-4f15-b656-4edcc2b5ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@return_default_value_if_fails(default_value='')\n",
    "def collect_predictions(result):\n",
    "    print(result.masks.data.shape)\n",
    "#     rescaled_mask = F.interpolate(result.masks.data.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "#     rescaled_mask = rescaled_mask.squeeze(0)\n",
    "    masks = result.masks.data.cpu().numpy()\n",
    "    classes = result.boxes.cls.cpu().tolist()\n",
    "    confs = result.boxes.conf.cpu().numpy()\n",
    "    prediction_string = []\n",
    "\n",
    "    for pred, conf, mask in zip(classes, confs, masks):\n",
    "        if pred > 0:\n",
    "            continue\n",
    "        mask = mask.astype(bool)\n",
    "        encoded_mask = 'encoded' #encode_binary_mask(mask).decode('utf-8')\n",
    "        prediction_string.append(f\"{int(pred)} {conf} {encoded_mask}\")    \n",
    "    return \" \".join(prediction_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "63a8a3c3-201d-4599-ae8f-4b5f0fc3d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @return_default_value_if_fails(default_value='')\n",
    "def collect_predictions_nms(boxes, masks):\n",
    "#     rescaled_mask = F.interpolate(result.masks.data.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "#     rescaled_mask = rescaled_mask.squeeze(0)\n",
    "    masks = masks.cpu().numpy()\n",
    "    classes = boxes[:, 5].cpu().tolist()\n",
    "    confs = boxes[:, 4].cpu().numpy()\n",
    "    prediction_string = []\n",
    "\n",
    "    for pred, conf, mask in zip(classes, confs, masks):\n",
    "        if pred > 0:\n",
    "            continue\n",
    "        mask = mask.astype(bool)\n",
    "        encoded_mask = 'encoded' #encode_binary_mask(mask).decode('utf-8')\n",
    "        prediction_string.append(f\"{int(pred)} {conf} {encoded_mask}\")    \n",
    "    return \" \".join(prediction_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5732b95f-e53f-46c4-b896-06b1e7ce5d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ilia_kiselev/Figure_1.png']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('/home/ilia_kiselev/Figure_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "48166e57-23c3-48e2-92ae-9b96bc8d253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 166 blood_vessels, 2 glomeruluss, 3 FTEs, 317.5ms\n",
      "Speed: 6.5ms preprocess, 317.5ms inference, 167.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 164 blood_vessels, 4 glomeruluss, 324.9ms\n",
      "Speed: 6.6ms preprocess, 324.9ms inference, 221.7ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "ids = []\n",
    "heights = []\n",
    "widths = []\n",
    "prediction_strings = []\n",
    "\n",
    "  \n",
    "for image in glob('/media/ilia_kiselev/Datasets/hubmap-hacking-the-human-vasculature/test/*'):\n",
    "    with Image.open(image) as im:\n",
    "        in_mem_file = io.BytesIO()\n",
    "        im.save(in_mem_file, format='JPEG')\n",
    "        in_mem_file.seek(0)\n",
    "        im_jpg = Image.open(in_mem_file)\n",
    "    res = []\n",
    "    for m_idx, model in enumerate(models):\n",
    "        for result in model(im_jpg, conf=0.001, iou=0.7, max_det=300, retina_masks=True):\n",
    "            if result.masks:\n",
    "                masks = result.masks.data\n",
    "                boxes = result.boxes.data\n",
    "                classes = one_hot(boxes[:, 5].long(), num_classes=8) * boxes[:, 4].unsqueeze(1).to(boxes.device)\n",
    "                index = torch.arange(len(boxes)).to(boxes.device).unsqueeze(1)\n",
    "                m = torch.ones_like(index).to(boxes.device) * m_idx\n",
    "                res.append((\n",
    "                    torch.cat(\n",
    "                        (boxes[:, :4], classes, boxes[:, 4:6], index, m),\n",
    "                        dim=1\n",
    "                    ),\n",
    "                    masks\n",
    "                ))\n",
    "            break\n",
    "    if res:\n",
    "        all_boxes = torch.cat([r[0] for r in res])\n",
    "        all_boxes = all_boxes.transpose(1,0).unsqueeze(0)\n",
    "        nms_boxes = non_max_suppression(\n",
    "            all_boxes,\n",
    "            conf_thres=0.001,\n",
    "            iou_thres=0.7,\n",
    "            max_det=300,\n",
    "            nc = 8\n",
    "        )[0]\n",
    "        unique_models = torch.unique(nms_boxes[:, 9])\n",
    "        split_tensors = {m.item(): nms_boxes[nms_boxes[:, 9] == m] for m in unique_models}\n",
    "        nms_masks = []\n",
    "        nms_preds = []\n",
    "        for m, preds in split_tensors.items():\n",
    "            masks = res[int(m)][1]\n",
    "            masks = masks[preds[:, 8].long()]\n",
    "            nms_masks.append(masks)\n",
    "            nms_preds.append(preds)\n",
    "        nms_masks = torch.cat(nms_masks)\n",
    "        nms_boxes = torch.cat(nms_preds)[:, :6]\n",
    "        prediction_strings.append(collect_predictions_nms(nms_boxes, nms_masks))\n",
    "    else:\n",
    "        prediction_strings.append('')\n",
    "    ids.append(image.split(\"/\")[-1].split(\".\")[0])\n",
    "    h, w = result.orig_shape\n",
    "    heights.append(h)\n",
    "    widths.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "efd4d569-02a5-4403-95bf-6d129467b8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1264e+02,  1.0245e+02,  5.3438e+02,  3.8535e+02,  7.4424e-01,  0.0000e+00],\n",
       "        [ 9.5412e+01,  1.9949e+02,  3.9584e+02,  6.8522e+02,  6.4378e-01,  0.0000e+00],\n",
       "        [ 5.3496e+00,  1.0437e+02,  4.0264e+02,  5.3261e+02,  4.2012e-01,  0.0000e+00],\n",
       "        [ 2.1909e+02,  8.6081e+01,  7.2534e+02,  3.4592e+02,  3.3954e-01,  0.0000e+00],\n",
       "        [ 1.2531e+02,  2.2616e+02,  4.9748e+02,  7.3807e+02,  2.6287e-01,  0.0000e+00],\n",
       "        [ 1.0894e+02, -2.5101e+01,  5.5702e+02,  2.5286e+01,  2.2370e-01,  2.0000e+00],\n",
       "        [-3.1366e+01,  1.1759e+01,  3.7204e+02,  4.5637e+02,  5.1673e-02,  0.0000e+00],\n",
       "        [ 1.7831e+02,  1.0116e+02,  6.3063e+02,  4.1391e+02,  4.5357e-02,  0.0000e+00],\n",
       "        [-7.6191e+01, -5.9073e+01,  1.9967e+02,  5.9517e+01,  3.1084e-02,  0.0000e+00],\n",
       "        [ 1.3333e+01,  1.8701e+01,  1.4062e+02,  1.3034e+02,  2.0997e-02,  0.0000e+00],\n",
       "        [-1.5578e+02,  1.2646e+01,  2.3369e+02,  4.9348e+02,  1.3970e-02,  0.0000e+00],\n",
       "        [ 2.1869e+02,  2.0238e+02,  7.1398e+02,  6.5310e+02,  1.2900e-02,  0.0000e+00],\n",
       "        [ 1.6461e+01,  6.1025e+01,  1.0445e+02,  2.1747e+02,  1.0374e-02,  0.0000e+00],\n",
       "        [ 6.3799e+01,  1.7044e+02,  2.7514e+02,  5.8356e+02,  9.9027e-03,  0.0000e+00],\n",
       "        [ 1.8735e+01,  2.5895e+01,  4.9324e+02,  2.6723e+02,  8.8497e-03,  0.0000e+00],\n",
       "        [-7.9184e+01, -5.6435e+01,  1.8436e+02,  5.6904e+01,  7.8352e-03,  2.0000e+00],\n",
       "        [-1.4930e+02, -1.0279e+02,  1.5015e+02,  1.0279e+02,  7.0195e-03,  0.0000e+00],\n",
       "        [-7.3956e+01,  6.1996e+01,  2.8595e+02,  5.1487e+02,  5.1834e-03,  0.0000e+00],\n",
       "        [-1.3152e+02,  1.0681e+02,  2.4563e+02,  5.7108e+02,  4.8487e-03,  0.0000e+00],\n",
       "        [ 5.2242e+01,  2.4566e+02,  2.0218e+02,  7.5742e+02,  4.6450e-03,  0.0000e+00],\n",
       "        [ 9.5152e+01,  1.0501e+02,  6.0460e+02,  6.0907e+02,  4.4210e-03,  0.0000e+00],\n",
       "        [ 8.9412e+00,  4.5360e+01,  6.1599e+01,  1.8186e+02,  4.3049e-03,  0.0000e+00],\n",
       "        [ 5.8764e+00,  1.8339e+02,  1.8295e+02,  6.9318e+02,  3.9818e-03,  0.0000e+00],\n",
       "        [ 1.3177e+01,  1.6187e+02,  2.2974e+02,  5.8514e+02,  3.9444e-03,  0.0000e+00],\n",
       "        [-4.1565e+01,  1.1851e+02,  2.7314e+02,  6.1284e+02,  3.3508e-03,  0.0000e+00],\n",
       "        [-2.8110e+01, -1.7038e+01,  4.7438e+02,  3.0833e+02,  3.2288e-03,  0.0000e+00],\n",
       "        [-8.2141e+01, -3.0615e+01,  3.7637e+02,  3.2200e+01,  3.2143e-03,  0.0000e+00],\n",
       "        [-8.7716e+01, -1.3080e+01,  9.1378e+01,  1.3692e+01,  3.1178e-03,  0.0000e+00],\n",
       "        [ 5.0588e+00,  1.8747e+02,  3.1124e+02,  6.9469e+02,  3.1145e-03,  0.0000e+00],\n",
       "        [ 6.2091e+01,  1.7981e+02,  5.4144e+02,  6.9164e+02,  2.9074e-03,  0.0000e+00],\n",
       "        [ 2.2425e+02,  1.1258e+02,  7.3598e+02,  4.2031e+02,  2.7549e-03,  0.0000e+00],\n",
       "        [-3.5670e+01,  2.3913e+02,  2.4255e+02,  7.5086e+02,  2.5464e-03,  1.0000e+00],\n",
       "        [ 2.5114e+01, -2.8712e+01,  4.6962e+02,  2.9653e+01,  2.1484e-03,  0.0000e+00],\n",
       "        [-9.5352e+01, -9.1282e+01,  1.6952e+02,  9.2494e+01,  2.1352e-03,  0.0000e+00],\n",
       "        [-1.5111e+02, -7.3860e+01,  2.6223e+02,  7.5256e+01,  2.0827e-03,  0.0000e+00],\n",
       "        [ 1.3218e+01,  1.6940e+02,  4.0541e+02,  6.6081e+02,  2.0141e-03,  0.0000e+00],\n",
       "        [-1.0626e+02, -1.7593e+01,  1.0994e+02,  1.8202e+01,  1.9819e-03,  0.0000e+00],\n",
       "        [-3.2002e+00,  3.7625e+01,  8.7499e+01,  2.0661e+02,  1.6057e-03,  0.0000e+00],\n",
       "        [ 5.5868e+01,  1.1196e+02,  5.2859e+02,  4.5770e+02,  1.5713e-03,  0.0000e+00],\n",
       "        [ 1.0256e+02,  3.6537e+01,  3.7287e+02,  1.3331e+02,  1.5158e-03,  0.0000e+00],\n",
       "        [ 1.9584e+02, -1.9840e+01,  7.0754e+02,  2.5309e+02,  1.5099e-03,  2.0000e+00],\n",
       "        [ 7.6676e+01,  1.3838e+02,  2.7625e+02,  4.5705e+02,  1.5011e-03,  0.0000e+00],\n",
       "        [-3.4449e+01, -6.2715e+01,  4.7637e+02,  4.4929e+02,  1.1511e-03,  0.0000e+00],\n",
       "        [-3.4191e+01, -1.6534e+01,  3.5295e+01,  1.6534e+01,  1.1122e-03,  0.0000e+00],\n",
       "        [-5.5613e+00,  2.2122e+01,  2.7857e+01,  9.2948e+01,  1.0764e-03,  0.0000e+00],\n",
       "        [-1.5392e+02, -1.5442e+02,  1.5392e+02,  1.6079e+02,  1.0025e-03,  0.0000e+00],\n",
       "        [-5.4899e-01, -2.9949e+01,  1.2514e+02,  8.3800e+01,  5.2349e-01,  0.0000e+00],\n",
       "        [ 1.8297e+02,  2.1982e+02,  6.5730e+02,  7.2973e+02,  5.0771e-01,  0.0000e+00],\n",
       "        [ 6.8092e+01,  2.4205e+02,  2.9597e+02,  7.5376e+02,  3.5507e-01,  0.0000e+00],\n",
       "        [-4.1763e+01, -7.5516e+00,  4.4281e+01,  9.0017e+00,  3.1601e-01,  0.0000e+00],\n",
       "        [-1.6835e+01,  1.6160e+01,  1.7072e+01,  8.8553e+01,  2.5561e-01,  0.0000e+00],\n",
       "        [ 7.0947e+01,  4.8571e+01,  3.0575e+02,  2.0584e+02,  1.8593e-01,  0.0000e+00],\n",
       "        [ 1.3868e+02,  1.2794e+02,  4.9424e+02,  4.4058e+02,  1.7398e-01,  0.0000e+00],\n",
       "        [-4.2372e+01, -1.3234e+01,  4.5206e+01,  1.3405e+01,  1.4546e-01,  0.0000e+00],\n",
       "        [ 7.0972e+01,  1.4184e+02,  3.1178e+02,  5.1252e+02,  1.1955e-01,  0.0000e+00],\n",
       "        [ 1.7945e+02,  1.7967e+02,  6.3152e+02,  6.1599e+02,  1.1720e-01,  0.0000e+00],\n",
       "        [ 3.8964e+01,  7.9316e+01,  2.5283e+02,  2.8233e+02,  9.2612e-02,  0.0000e+00],\n",
       "        [ 3.2988e+01,  1.1163e+02,  2.0775e+02,  3.8551e+02,  6.8938e-02,  0.0000e+00],\n",
       "        [-1.3919e+02, -1.4236e+01,  1.3919e+02,  4.9441e+02,  5.0441e-02,  0.0000e+00],\n",
       "        [-5.1638e+01, -9.7230e+00,  5.1940e+01,  1.0488e+01,  4.9510e-02,  0.0000e+00],\n",
       "        [-8.9852e+01, -2.3498e+01,  8.9852e+01,  4.8237e+02,  4.8189e-02,  0.0000e+00],\n",
       "        [ 1.9928e+02,  5.1862e+01,  7.0972e+02,  2.4253e+02,  4.7034e-02,  0.0000e+00],\n",
       "        [-1.7149e+01,  2.9770e+01,  1.7415e+01,  2.3041e+02,  3.7014e-02,  0.0000e+00],\n",
       "        [-6.8657e+00,  2.8619e+01,  4.8327e+01,  1.3721e+02,  3.6961e-02,  0.0000e+00],\n",
       "        [-7.0784e+01,  1.1630e+02,  1.9247e+02,  6.2299e+02,  3.4008e-02,  0.0000e+00],\n",
       "        [-2.1860e+01,  6.0520e+00,  2.1951e+01,  8.0165e+01,  2.6558e-02,  0.0000e+00],\n",
       "        [-1.1055e+02,  7.4284e+01,  1.1055e+02,  5.8628e+02,  2.5274e-02,  0.0000e+00],\n",
       "        [-2.7783e+01, -5.8217e+00,  3.7107e+01,  6.1183e+00,  2.4115e-02,  0.0000e+00],\n",
       "        [ 2.0550e+02,  2.4361e+01,  6.6980e+02,  1.2562e+02,  2.1086e-02,  0.0000e+00],\n",
       "        [-5.4998e+01,  5.0082e+01,  4.5700e+02,  5.6208e+02,  1.4806e-02,  0.0000e+00],\n",
       "        [-7.5355e+01, -3.6436e+01,  7.5355e+01,  3.6436e+01,  1.4460e-02,  0.0000e+00],\n",
       "        [ 2.1214e+02,  2.5788e+01,  7.2351e+02,  2.9424e+02,  1.3814e-02,  0.0000e+00],\n",
       "        [ 5.6765e+01,  2.8434e+01,  3.2931e+02,  1.3726e+02,  1.3334e-02,  0.0000e+00],\n",
       "        [-5.8540e+01, -1.5162e+01,  5.8540e+01,  1.5162e+01,  1.1617e-02,  0.0000e+00],\n",
       "        [ 2.4603e+02,  2.5063e+02,  7.5797e+02,  7.6240e+02,  1.0628e-02,  0.0000e+00],\n",
       "        [ 3.0239e+00,  3.4824e+01,  5.3698e+01,  1.4150e+02,  9.8899e-03,  0.0000e+00],\n",
       "        [ 2.1390e+01,  8.5836e+01,  1.6387e+02,  3.4586e+02,  8.6266e-03,  0.0000e+00],\n",
       "        [ 1.4888e+02,  9.4021e+01,  4.8750e+02,  3.2494e+02,  8.0183e-03,  0.0000e+00],\n",
       "        [-2.1701e+01, -5.3757e+00,  2.5482e+01,  5.7322e+00,  6.7521e-03,  0.0000e+00],\n",
       "        [-1.0324e+02, -5.3035e+01,  1.0324e+02,  5.3035e+01,  4.8112e-03,  0.0000e+00],\n",
       "        [ 2.4898e+02,  1.4374e+02,  7.6077e+02,  4.9579e+02,  4.6771e-03,  0.0000e+00],\n",
       "        [ 2.1785e+01,  2.5271e+02,  1.1300e+02,  7.6451e+02,  3.5737e-03,  0.0000e+00],\n",
       "        [-1.2243e+02, -1.0853e+02,  1.5668e+02,  1.0941e+02,  3.2921e-03,  1.0000e+00],\n",
       "        [-4.6379e+01, -3.1974e+01,  4.8455e+01,  3.2366e+01,  3.1153e-03,  0.0000e+00],\n",
       "        [ 2.2068e+02,  4.6088e+01,  7.3253e+02,  1.8131e+02,  2.8858e-03,  0.0000e+00],\n",
       "        [-7.4922e+01, -8.5804e+01,  7.8254e+01,  4.2620e+02,  2.6188e-03,  0.0000e+00],\n",
       "        [ 4.4690e+01,  5.0595e+01,  1.5695e+02,  1.7650e+02,  2.5640e-03,  0.0000e+00],\n",
       "        [ 1.7160e+02,  7.5865e+01,  6.5013e+02,  3.1466e+02,  2.4267e-03,  0.0000e+00],\n",
       "        [-5.6048e+00, -5.8143e+00,  7.8435e+01,  6.2298e+00,  2.2924e-03,  0.0000e+00],\n",
       "        [-1.5326e+01, -3.4388e+01,  2.4992e+02,  3.5830e+01,  2.1433e-03,  1.0000e+00],\n",
       "        [-2.7129e-01,  6.8764e+01,  7.1565e+01,  2.5586e+02,  2.1108e-03,  0.0000e+00],\n",
       "        [-3.5306e+01, -1.0606e+01,  3.8984e+01,  1.0606e+01,  2.0945e-03,  0.0000e+00],\n",
       "        [ 5.8333e+01, -2.9105e+00,  1.9854e+02,  2.9811e+00,  2.0868e-03,  0.0000e+00],\n",
       "        [ 1.1856e+02, -2.4587e+01,  5.6698e+02,  2.5438e+01,  1.9526e-03,  0.0000e+00],\n",
       "        [-3.3555e+00, -2.7098e+00,  3.3555e+00,  2.7098e+00,  1.8133e-03,  0.0000e+00],\n",
       "        [ 5.5900e+01, -4.0555e+00,  1.9714e+02,  4.2693e+00,  1.7507e-03,  0.0000e+00],\n",
       "        [-6.2754e+01, -4.7059e+01,  6.4499e+01,  4.8321e+01,  1.6261e-03,  0.0000e+00],\n",
       "        [-2.4768e+01, -7.6813e+00,  2.6023e+01,  7.7594e+00,  1.5789e-03,  0.0000e+00],\n",
       "        [-6.7374e+01,  1.8288e+02,  2.4191e+02,  6.9329e+02,  1.5206e-03,  0.0000e+00],\n",
       "        [-1.5291e+01, -5.3262e+00,  5.9002e+01,  5.6205e+00,  1.4869e-03,  0.0000e+00],\n",
       "        [ 2.0019e+02, -4.5321e+00,  7.0391e+02,  4.6300e+00,  1.4844e-03,  0.0000e+00],\n",
       "        [ 1.4383e+02, -1.6130e+01,  5.9124e+02,  1.7005e+01,  1.4137e-03,  0.0000e+00],\n",
       "        [-1.2337e+01,  2.5246e+02,  1.2337e+01,  7.6437e+02,  1.2633e-03,  0.0000e+00],\n",
       "        [-3.1341e+00, -4.0621e+00,  3.1341e+00,  4.0621e+00,  1.0736e-03,  0.0000e+00],\n",
       "        [-1.3107e+02, -1.6651e+02,  1.3107e+02,  1.8300e+02,  1.0388e-03,  1.0000e+00],\n",
       "        [-3.1505e+01, -8.1989e+00,  1.0370e+02,  8.1989e+00,  1.0333e-03,  0.0000e+00],\n",
       "        [-5.6253e+01, -4.0548e+01,  3.2680e+02,  4.2990e+01,  1.0068e-03,  1.0000e+00]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b217676-6d51-4f62-8712-36b492c05884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 8].long().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a4dc1cf-00a3-4d4b-ae3f-86cab57c15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 8\n",
    "prediction=all_boxes\n",
    "conf_thres = 0.001\n",
    "bs = prediction.shape[0]  # batch size\n",
    "nc = nc or (prediction.shape[1] - 4)  # number of classes\n",
    "nm = prediction.shape[1] - nc - 4\n",
    "mi = 4 + nc  # mask start index\n",
    "xc = prediction[:, 4:mi].amax(1) > conf_thres  # candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c5ccb0e-ca1e-4ae5-a031-b738c8eb063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:, 4:mi].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a922cd8b-09de-47b1-b028-9dbbf6613da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 339])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_boxes.transpose(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99a79651-4d9b-49e3-9c77-585942930d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f242cf5f-de20-47c1-9faf-4b50e64a1535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_boxes[:, 5].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "caee1ccf-a0ba-4043-a54d-dbdd4dd9c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7442, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.6438, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4201, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0010, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0010, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0010, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(all_boxes[:, 5].long(), num_classes=8) * all_boxes[:, 4].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aea08780-9e1e-4a92-b343-f5e3d5502973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[323.3514, 245.5656, 419.8745,  ...,   0.0000,   0.0000,   1.0000],\n",
       "        [ 62.2975,  26.9251, 125.6931,  ...,   0.0000,   1.0000,   1.0000],\n",
       "        [420.1374, 474.7765, 474.3341,  ...,   0.0000,   2.0000,   1.0000],\n",
       "        ...,\n",
       "        [ 75.3165, 358.2346, 216.8940,  ...,   0.0000, 165.0000,   1.0000],\n",
       "        [135.2725,   1.2211, 383.0518,  ...,   1.0000, 166.0000,   1.0000],\n",
       "        [342.9461, 429.6335, 466.5449,  ...,   0.0000, 167.0000,   1.0000]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c3ea9a-40e7-4c4f-aa9e-3def311742a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = result.masks.data\n",
    "classes = result.boxes.cls\n",
    "confs = result.boxes.conf\n",
    "boxes = result.boxes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094edef0-99fb-49b0-b28a-7a4a6edea1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((boxes,torch.arange(len(boxes)).to(boxes.device).unsqueeze(1)), dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949e6016-76d7-416a-9b9d-dd20fa2cd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.yolo.utils.ops import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34e9500b-456d-4b8e-ad3d-58d5c6c07f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_max_suppression(\n",
    "    torch.cat((boxes,torch.arange(len(boxes)).to(boxes.device).unsqueeze(1)), dim=1),\n",
    "    conf_thres=0.001,\n",
    "    iou_thres=0.7,\n",
    "    max_det=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4cbd819-f593-4637-8dfe-3674e37af3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[323.5099, 243.9022, 421.7449,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [245.6263, 442.3592, 300.4283,  ...,   0.0000,   1.0000,   0.0000],\n",
       "         [203.9942, 318.4895, 397.2891,  ...,   0.0000,   2.0000,   0.0000],\n",
       "         ...,\n",
       "         [ 75.3165, 358.2346, 216.8940,  ...,   0.0000, 165.0000,   1.0000],\n",
       "         [135.2725,   1.2211, 383.0518,  ...,   1.0000, 166.0000,   1.0000],\n",
       "         [342.9461, 429.6335, 466.5449,  ...,   0.0000, 167.0000,   1.0000]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_boxes.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3476f-5574-4d5f-9f47-251b14096772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
